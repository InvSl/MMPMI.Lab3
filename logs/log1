2020-09-29 13:42:31.535617: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-29 13:42:32.886642: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-29 13:42:32.924625: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-09-29 13:42:32.925246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-09-29 13:42:32.925281: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-29 13:42:32.926961: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-29 13:42:32.928742: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-29 13:42:32.929070: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-29 13:42:32.930997: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-29 13:42:32.931978: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-29 13:42:32.935864: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-09-29 13:42:32.935970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-09-29 13:42:32.936601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-09-29 13:42:32.937112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-09-29 13:42:32.942723: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz
2020-09-29 13:42:32.942907: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x12f2a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-29 13:42:32.942935: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-29 13:42:33.051464: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-09-29 13:42:33.052090: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x12f2f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-09-29 13:42:33.052121: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2020-09-29 13:42:33.052331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-09-29 13:42:33.052853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-09-29 13:42:33.052904: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-29 13:42:33.052941: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-29 13:42:33.052971: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-29 13:42:33.052990: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-29 13:42:33.053008: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-29 13:42:33.053027: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-29 13:42:33.053047: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-09-29 13:42:33.053128: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-09-29 13:42:33.053731: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-09-29 13:42:33.054245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-09-29 13:42:33.054291: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-29 13:42:33.661564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-29 13:42:33.661620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2020-09-29 13:42:33.661632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2020-09-29 13:42:33.661807: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-09-29 13:42:33.662376: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-09-29 13:42:33.662883: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-09-29 13:42:33.662926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.
2020-09-29 13:42:35.578011: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.
2020-09-29 13:42:35.578093: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1391] Profiler found 1 GPUs
2020-09-29 13:42:35.578915: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcupti.so.10.1
2020-09-29 13:42:35.716683: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1513] CUPTI activity buffer flushed
Epoch 1/30
2020-09-29 13:42:39.330045: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-29 13:42:40.163574: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
      1/Unknown - 0s 616us/step - loss: 2.4400 - categorical_accuracy: 0.04692020-09-29 13:42:44.877817: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.
Instructions for updating:
use `tf.profiler.experimental.stop` instead.
2020-09-29 13:42:45.315595: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1513] CUPTI activity buffer flushed
2020-09-29 13:42:45.348342: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:223]  GpuTracer has collected 1300 callback api events and 1300 activity events. 
2020-09-29 13:42:45.499587: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: drive/My Drive/logs1/ilcd-1601386955.5778716/train/plugins/profile/2020_09_29_13_42_45
2020-09-29 13:42:45.590244: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for trace.json.gz to drive/My Drive/logs1/ilcd-1601386955.5778716/train/plugins/profile/2020_09_29_13_42_45/4c294bb40ad3.trace.json.gz
2020-09-29 13:42:45.693317: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: drive/My Drive/logs1/ilcd-1601386955.5778716/train/plugins/profile/2020_09_29_13_42_45
2020-09-29 13:42:45.707494: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for memory_profile.json.gz to drive/My Drive/logs1/ilcd-1601386955.5778716/train/plugins/profile/2020_09_29_13_42_45/4c294bb40ad3.memory_profile.json.gz
2020-09-29 13:42:45.760012: I tensorflow/python/profiler/internal/profiler_wrapper.cc:111] Creating directory: drive/My Drive/logs1/ilcd-1601386955.5778716/train/plugins/profile/2020_09_29_13_42_45Dumped tool data for xplane.pb to drive/My Drive/logs1/ilcd-1601386955.5778716/train/plugins/profile/2020_09_29_13_42_45/4c294bb40ad3.xplane.pb
Dumped tool data for overview_page.pb to drive/My Drive/logs1/ilcd-1601386955.5778716/train/plugins/profile/2020_09_29_13_42_45/4c294bb40ad3.overview_page.pb
Dumped tool data for input_pipeline.pb to drive/My Drive/logs1/ilcd-1601386955.5778716/train/plugins/profile/2020_09_29_13_42_45/4c294bb40ad3.input_pipeline.pb
Dumped tool data for tensorflow_stats.pb to drive/My Drive/logs1/ilcd-1601386955.5778716/train/plugins/profile/2020_09_29_13_42_45/4c294bb40ad3.tensorflow_stats.pb
Dumped tool data for kernel_stats.pb to drive/My Drive/logs1/ilcd-1601386955.5778716/train/plugins/profile/2020_09_29_13_42_45/4c294bb40ad3.kernel_stats.pb

      2/Unknown - 1s 448ms/step - loss: 2.3063 - categorical_accuracy: 0.1094WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1155s vs `on_train_batch_end` time: 0.7790s). Check your callbacks.
220/220 [==============================] - 105s 476ms/step - loss: 0.9447 - categorical_accuracy: 0.5831 - val_loss: 3.2821 - val_categorical_accuracy: 0.1843
Epoch 2/30
220/220 [==============================] - 104s 472ms/step - loss: 0.6812 - categorical_accuracy: 0.6825 - val_loss: 3.7005 - val_categorical_accuracy: 0.1843
Epoch 3/30
220/220 [==============================] - 103s 470ms/step - loss: 0.8570 - categorical_accuracy: 0.6258 - val_loss: 4.3940 - val_categorical_accuracy: 0.1850
Epoch 4/30
220/220 [==============================] - 104s 471ms/step - loss: 0.8813 - categorical_accuracy: 0.6537 - val_loss: 4.7838 - val_categorical_accuracy: 0.1843
Epoch 5/30
220/220 [==============================] - 104s 471ms/step - loss: 0.7354 - categorical_accuracy: 0.6878 - val_loss: 4.1839 - val_categorical_accuracy: 0.1887
Epoch 6/30
220/220 [==============================] - 103s 470ms/step - loss: 0.7320 - categorical_accuracy: 0.6895 - val_loss: 3.7684 - val_categorical_accuracy: 0.2017
Epoch 7/30
220/220 [==============================] - 104s 471ms/step - loss: 0.7829 - categorical_accuracy: 0.6758 - val_loss: 3.2651 - val_categorical_accuracy: 0.3037
Epoch 8/30
220/220 [==============================] - 103s 470ms/step - loss: 0.6928 - categorical_accuracy: 0.6781 - val_loss: 2.6459 - val_categorical_accuracy: 0.3840
Epoch 9/30
220/220 [==============================] - 102s 465ms/step - loss: 0.5833 - categorical_accuracy: 0.6999 - val_loss: 2.5405 - val_categorical_accuracy: 0.4343
Epoch 10/30
220/220 [==============================] - 103s 469ms/step - loss: 0.6020 - categorical_accuracy: 0.6979 - val_loss: 2.2960 - val_categorical_accuracy: 0.4100
Epoch 11/30
220/220 [==============================] - 104s 472ms/step - loss: 0.6275 - categorical_accuracy: 0.6865 - val_loss: 2.1056 - val_categorical_accuracy: 0.4413
Epoch 12/30
220/220 [==============================] - 100s 454ms/step - loss: 0.5619 - categorical_accuracy: 0.6950 - val_loss: 1.8229 - val_categorical_accuracy: 0.4203
Epoch 13/30
220/220 [==============================] - 104s 471ms/step - loss: 0.5321 - categorical_accuracy: 0.6947 - val_loss: 1.5627 - val_categorical_accuracy: 0.4640
Epoch 14/30
220/220 [==============================] - 99s 451ms/step - loss: 0.4737 - categorical_accuracy: 0.7093 - val_loss: 1.5177 - val_categorical_accuracy: 0.4563
Epoch 15/30
220/220 [==============================] - 103s 470ms/step - loss: 0.4897 - categorical_accuracy: 0.7078 - val_loss: 1.4187 - val_categorical_accuracy: 0.4700
Epoch 16/30
220/220 [==============================] - 103s 470ms/step - loss: 0.4396 - categorical_accuracy: 0.7188 - val_loss: 1.3683 - val_categorical_accuracy: 0.4860
Epoch 17/30
220/220 [==============================] - 104s 471ms/step - loss: 0.4374 - categorical_accuracy: 0.7196 - val_loss: 1.4837 - val_categorical_accuracy: 0.4313
Epoch 18/30
220/220 [==============================] - 104s 472ms/step - loss: 0.3992 - categorical_accuracy: 0.7279 - val_loss: 1.3034 - val_categorical_accuracy: 0.4887
Epoch 19/30
220/220 [==============================] - 99s 450ms/step - loss: 0.3895 - categorical_accuracy: 0.7302 - val_loss: 1.3451 - val_categorical_accuracy: 0.4343
Epoch 20/30
220/220 [==============================] - 104s 471ms/step - loss: 0.3933 - categorical_accuracy: 0.7296 - val_loss: 1.1686 - val_categorical_accuracy: 0.4740
Epoch 21/30
220/220 [==============================] - 104s 472ms/step - loss: 0.3613 - categorical_accuracy: 0.7366 - val_loss: 1.0315 - val_categorical_accuracy: 0.5100
Epoch 22/30
220/220 [==============================] - 104s 472ms/step - loss: 0.3652 - categorical_accuracy: 0.7346 - val_loss: 1.0417 - val_categorical_accuracy: 0.5087
Epoch 23/30
220/220 [==============================] - 100s 454ms/step - loss: 0.3489 - categorical_accuracy: 0.7358 - val_loss: 1.0698 - val_categorical_accuracy: 0.4967
Epoch 24/30
220/220 [==============================] - 103s 470ms/step - loss: 0.3336 - categorical_accuracy: 0.7412 - val_loss: 1.0562 - val_categorical_accuracy: 0.5033
Epoch 25/30
220/220 [==============================] - 100s 455ms/step - loss: 0.3265 - categorical_accuracy: 0.7427 - val_loss: 0.9830 - val_categorical_accuracy: 0.5203
Epoch 26/30
220/220 [==============================] - 104s 471ms/step - loss: 0.3180 - categorical_accuracy: 0.7448 - val_loss: 0.9735 - val_categorical_accuracy: 0.5240
Epoch 27/30
220/220 [==============================] - 104s 472ms/step - loss: 0.3127 - categorical_accuracy: 0.7463 - val_loss: 0.9087 - val_categorical_accuracy: 0.5500
Epoch 28/30
220/220 [==============================] - 102s 466ms/step - loss: 0.3231 - categorical_accuracy: 0.7421 - val_loss: 0.9469 - val_categorical_accuracy: 0.5440
Epoch 29/30
220/220 [==============================] - 100s 452ms/step - loss: 0.3089 - categorical_accuracy: 0.7437 - val_loss: 0.8558 - val_categorical_accuracy: 0.5630
Epoch 30/30
220/220 [==============================] - 104s 473ms/step - loss: 0.3036 - categorical_accuracy: 0.7458 - val_loss: 0.9205 - val_categorical_accuracy: 0.5413
