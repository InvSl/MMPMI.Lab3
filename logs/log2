2020-09-29 13:42:29.733175: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-29 13:42:31.153946: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-29 13:42:31.193725: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-09-29 13:42:31.194401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-09-29 13:42:31.194451: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-29 13:42:31.196230: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-29 13:42:31.198077: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-29 13:42:31.198453: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-29 13:42:31.200459: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-29 13:42:31.201326: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-29 13:42:31.205287: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-09-29 13:42:31.205424: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-09-29 13:42:31.206052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-09-29 13:42:31.206632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-09-29 13:42:31.212775: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz
2020-09-29 13:42:31.212998: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x186ea00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-29 13:42:31.213030: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-29 13:42:31.324637: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-09-29 13:42:31.325400: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x186ef40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-09-29 13:42:31.325433: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2020-09-29 13:42:31.325635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-09-29 13:42:31.326213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s
2020-09-29 13:42:31.326261: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-29 13:42:31.326302: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-29 13:42:31.326328: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-29 13:42:31.326367: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-29 13:42:31.326391: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-29 13:42:31.326413: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-29 13:42:31.326437: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-09-29 13:42:31.326509: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-09-29 13:42:31.327096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-09-29 13:42:31.327644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-09-29 13:42:31.327694: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-29 13:42:31.951883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-29 13:42:31.951946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2020-09-29 13:42:31.951960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2020-09-29 13:42:31.952149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-09-29 13:42:31.952838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-09-29 13:42:31.953407: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-09-29 13:42:31.953479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.
2020-09-29 13:42:33.993532: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.
2020-09-29 13:42:33.993631: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1391] Profiler found 1 GPUs
2020-09-29 13:42:33.994470: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcupti.so.10.1
2020-09-29 13:42:34.137063: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1513] CUPTI activity buffer flushed
Epoch 1/30
2020-09-29 13:42:37.953957: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-29 13:42:38.655745: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
      1/Unknown - 0s 667us/step - loss: 2.3204 - categorical_accuracy: 0.10942020-09-29 13:42:43.687275: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.
Instructions for updating:
use `tf.profiler.experimental.stop` instead.
2020-09-29 13:42:44.134116: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1513] CUPTI activity buffer flushed
2020-09-29 13:42:44.175291: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:223]  GpuTracer has collected 1285 callback api events and 1285 activity events. 
2020-09-29 13:42:44.346086: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: drive/My Drive/logs2/ilcd-1601386953.993317/train/plugins/profile/2020_09_29_13_42_44
2020-09-29 13:42:44.446416: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for trace.json.gz to drive/My Drive/logs2/ilcd-1601386953.993317/train/plugins/profile/2020_09_29_13_42_44/47eb7c609f43.trace.json.gz
2020-09-29 13:42:44.550938: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: drive/My Drive/logs2/ilcd-1601386953.993317/train/plugins/profile/2020_09_29_13_42_44
2020-09-29 13:42:44.566547: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for memory_profile.json.gz to drive/My Drive/logs2/ilcd-1601386953.993317/train/plugins/profile/2020_09_29_13_42_44/47eb7c609f43.memory_profile.json.gz
2020-09-29 13:42:44.606163: I tensorflow/python/profiler/internal/profiler_wrapper.cc:111] Creating directory: drive/My Drive/logs2/ilcd-1601386953.993317/train/plugins/profile/2020_09_29_13_42_44Dumped tool data for xplane.pb to drive/My Drive/logs2/ilcd-1601386953.993317/train/plugins/profile/2020_09_29_13_42_44/47eb7c609f43.xplane.pb
Dumped tool data for overview_page.pb to drive/My Drive/logs2/ilcd-1601386953.993317/train/plugins/profile/2020_09_29_13_42_44/47eb7c609f43.overview_page.pb
Dumped tool data for input_pipeline.pb to drive/My Drive/logs2/ilcd-1601386953.993317/train/plugins/profile/2020_09_29_13_42_44/47eb7c609f43.input_pipeline.pb
Dumped tool data for tensorflow_stats.pb to drive/My Drive/logs2/ilcd-1601386953.993317/train/plugins/profile/2020_09_29_13_42_44/47eb7c609f43.tensorflow_stats.pb
Dumped tool data for kernel_stats.pb to drive/My Drive/logs2/ilcd-1601386953.993317/train/plugins/profile/2020_09_29_13_42_44/47eb7c609f43.kernel_stats.pb

      2/Unknown - 1s 466ms/step - loss: 2.2818 - categorical_accuracy: 0.1016WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1275s vs `on_train_batch_end` time: 0.8034s). Check your callbacks.
220/220 [==============================] - 105s 478ms/step - loss: 1.4807 - categorical_accuracy: 0.2678 - val_loss: 1.1449 - val_categorical_accuracy: 0.3757
Epoch 2/30
220/220 [==============================] - 104s 471ms/step - loss: 1.0704 - categorical_accuracy: 0.4191 - val_loss: 0.9410 - val_categorical_accuracy: 0.4543
Epoch 3/30
220/220 [==============================] - 103s 470ms/step - loss: 0.8627 - categorical_accuracy: 0.5098 - val_loss: 0.8257 - val_categorical_accuracy: 0.5077
Epoch 4/30
220/220 [==============================] - 104s 471ms/step - loss: 0.7308 - categorical_accuracy: 0.5630 - val_loss: 0.7557 - val_categorical_accuracy: 0.5357
Epoch 5/30
220/220 [==============================] - 104s 472ms/step - loss: 0.6472 - categorical_accuracy: 0.5971 - val_loss: 0.7113 - val_categorical_accuracy: 0.5543
Epoch 6/30
220/220 [==============================] - 102s 465ms/step - loss: 0.5905 - categorical_accuracy: 0.6268 - val_loss: 0.6951 - val_categorical_accuracy: 0.5613
Epoch 7/30
220/220 [==============================] - 103s 469ms/step - loss: 0.5685 - categorical_accuracy: 0.6331 - val_loss: 0.6836 - val_categorical_accuracy: 0.5667
Epoch 8/30
220/220 [==============================] - 104s 471ms/step - loss: 0.5559 - categorical_accuracy: 0.6441 - val_loss: 0.6961 - val_categorical_accuracy: 0.5660
Epoch 9/30
220/220 [==============================] - 104s 472ms/step - loss: 0.5529 - categorical_accuracy: 0.6523 - val_loss: 0.6880 - val_categorical_accuracy: 0.5690
Epoch 10/30
220/220 [==============================] - 101s 458ms/step - loss: 0.5466 - categorical_accuracy: 0.6546 - val_loss: 0.7150 - val_categorical_accuracy: 0.5627
Epoch 11/30
220/220 [==============================] - 104s 471ms/step - loss: 0.5550 - categorical_accuracy: 0.6573 - val_loss: 0.7448 - val_categorical_accuracy: 0.5513
Epoch 12/30
220/220 [==============================] - 103s 470ms/step - loss: 0.5820 - categorical_accuracy: 0.6582 - val_loss: 0.7542 - val_categorical_accuracy: 0.5560
Epoch 13/30
220/220 [==============================] - 102s 466ms/step - loss: 0.5827 - categorical_accuracy: 0.6562 - val_loss: 0.7561 - val_categorical_accuracy: 0.5657
Epoch 14/30
220/220 [==============================] - 104s 471ms/step - loss: 0.5834 - categorical_accuracy: 0.6571 - val_loss: 0.7597 - val_categorical_accuracy: 0.5667
Epoch 15/30
220/220 [==============================] - 103s 467ms/step - loss: 0.5933 - categorical_accuracy: 0.6553 - val_loss: 0.7402 - val_categorical_accuracy: 0.5760
Epoch 16/30
220/220 [==============================] - 104s 471ms/step - loss: 0.5906 - categorical_accuracy: 0.6564 - val_loss: 0.7383 - val_categorical_accuracy: 0.5760
Epoch 17/30
220/220 [==============================] - 103s 466ms/step - loss: 0.5951 - categorical_accuracy: 0.6549 - val_loss: 0.7286 - val_categorical_accuracy: 0.5857
Epoch 18/30
220/220 [==============================] - 103s 467ms/step - loss: 0.5892 - categorical_accuracy: 0.6605 - val_loss: 0.6838 - val_categorical_accuracy: 0.5983
Epoch 19/30
220/220 [==============================] - 100s 456ms/step - loss: 0.5930 - categorical_accuracy: 0.6528 - val_loss: 0.6774 - val_categorical_accuracy: 0.6007
Epoch 20/30
220/220 [==============================] - 103s 470ms/step - loss: 0.5898 - categorical_accuracy: 0.6583 - val_loss: 0.6556 - val_categorical_accuracy: 0.6123
Epoch 21/30
220/220 [==============================] - 103s 469ms/step - loss: 0.5843 - categorical_accuracy: 0.6618 - val_loss: 0.6380 - val_categorical_accuracy: 0.6177
Epoch 22/30
220/220 [==============================] - 103s 470ms/step - loss: 0.5725 - categorical_accuracy: 0.6669 - val_loss: 0.6265 - val_categorical_accuracy: 0.6247
Epoch 23/30
220/220 [==============================] - 101s 461ms/step - loss: 0.5721 - categorical_accuracy: 0.6663 - val_loss: 0.6134 - val_categorical_accuracy: 0.6297
Epoch 24/30
220/220 [==============================] - 104s 471ms/step - loss: 0.5637 - categorical_accuracy: 0.6665 - val_loss: 0.5912 - val_categorical_accuracy: 0.6407
Epoch 25/30
220/220 [==============================] - 104s 471ms/step - loss: 0.5632 - categorical_accuracy: 0.6703 - val_loss: 0.5927 - val_categorical_accuracy: 0.6393
Epoch 26/30
220/220 [==============================] - 104s 471ms/step - loss: 0.5461 - categorical_accuracy: 0.6747 - val_loss: 0.5840 - val_categorical_accuracy: 0.6440
Epoch 27/30
220/220 [==============================] - 103s 470ms/step - loss: 0.5473 - categorical_accuracy: 0.6743 - val_loss: 0.5643 - val_categorical_accuracy: 0.6497
Epoch 28/30
220/220 [==============================] - 101s 458ms/step - loss: 0.5374 - categorical_accuracy: 0.6734 - val_loss: 0.5428 - val_categorical_accuracy: 0.6557
Epoch 29/30
220/220 [==============================] - 103s 468ms/step - loss: 0.5256 - categorical_accuracy: 0.6771 - val_loss: 0.5265 - val_categorical_accuracy: 0.6600
Epoch 30/30
220/220 [==============================] - 103s 469ms/step - loss: 0.5116 - categorical_accuracy: 0.6816 - val_loss: 0.5238 - val_categorical_accuracy: 0.6630
